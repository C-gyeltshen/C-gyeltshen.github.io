---
Title: DAM101 Unit Two Journal
categories: [DAM101, Unit Two (Data Preprocessing)]
tags: [DAM101]
---
# Data Preprocessing

### What is DATA PREPROCESSING?

![question mark gif](https://gifsec.com/wp-content/uploads/2022/10/question-mark-1.gif)

Data preprocessing in machine learning is an important step that helps enhance the quality of data before feeding it into the model to extract meaningful output from the data.

### Why Data Preprocessing?

Data preprocessing helps make the raw data cleaner and more meaningful so that the machine, to which we feed the data, understands our data and learns the patterns in it, allowing us to obtain the best output from the data.

* **Improve the data quality**

Cleaning and refining raw data eliminates inaccuracies, missing values, and inconsistencies, ensuring that models are built on a clean and solid foundation.

Data preprocessing directly impacts the accuracy and conclusions drawn from the data. If the data is clean and well-organized, then the conclusions drawn will be more accurate.

* **Handling Missing Data**

Missing values, as the term itself implies, refer to values that are absent in the dataset, which can occur due to technological failures or human errors during data recording.

![missing value](https://miro.medium.com/v2/resize:fit:1400/1*LFbBwLXO4CC7txfDdrQBzw.jpeg)

 Missing values are handled using techniques such as imputation or removal of rows if the dataset is large. This ensures that analytical models are not skewed by the absence of crucial data points.

* **Standardizing and Normalizing**

Standardizing and normalizing data during data preprocessing steps ensures consistency. It transforms diverse scales and units into a standardized format to enable fair comparisons and prevent certain features from dominating others.

![example of normalizing data](https://miro.medium.com/v2/resize:fit:1400/1*kcoxtRYlkwCL8_rk0ntqMQ.png)

Example :

We have a dataset containing two features: "age" and "income." The "age" feature ranges from 0 to 100 years, while the "income" feature ranges from $2,000 to $200,000. Scaling these features so that they fall within a similar range, using methods like min-max scaling, allows us to scale the values between 0 and 1, making it more consistent for visualization and drawing conclusions.

* **Eliminating Duplicate Records**

Duplicate entries can distort analyses and mislead decision-making processes moreover it will increase the run time resulting in more use of computational memory.

**Data that are feed into the ML or Deep Learning Models are of different data type like :**

1. Numerical data 
2. Categorical data 
3. Tex data 
4. Image data 
5. Audio data

Each of the above data needs to be preprocessed  differently according to there own recruitment

